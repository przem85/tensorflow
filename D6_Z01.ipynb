{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # To support both python 2 and python 3# To su \n",
    "# from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual RNN\n",
    "\n",
    "  * Najpierw zaimplementujmy bardzo prosty model RNN, bez korzystania z żadnych operacji RNN TensorFlow, aby lepiej zrozumieć co dzieje się pod maską. \n",
    "\n",
    "  * Stworzymy RNN złożony z warstwy pięciu powtarzających się neuronów, wykorzystując funkcję aktywacji tanh. \n",
    "  \n",
    "  * Przyjmujemy, że RNN przebiega tylko w dwóch etapach, pobierając wektory wejściowe o rozmiarze $3$ w każdym kroku czasowym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons],dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons],dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sieć wygląda podobnie jak dwuwarstwowa sieć neuronowa, z małymi modyfikacjami: \n",
    "  * po pierwsze te same wagi i bias są wspódzielone przez obie warstwy, \n",
    "  \n",
    "  * po drugie przekaujemy dane wejściowe w każdej warstwie i otrzymujemy wyniki z każdej warstwy. \n",
    "  \n",
    "Aby uruchomić model, musimy wrzucić dane do obu etapów czasowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t = 0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Mini-batch zawiera cztery instancje, każda z sekwencją wejściowych złożona jest z dokładnie dwóch wejść.\n",
    "  \n",
    "  * Na końcu Y0_val i Y1_val zawierają dane wyjściowe sieci w obu etapach czasowych dla wszystkich neuronów i wszystkich instancji w mini-partii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33327058 -0.9674539   0.9919549  -0.9994455  -0.09661405]\n",
      " [ 0.9771993  -0.99999994  0.99999964 -1.         -0.5490335 ]\n",
      " [ 0.9994682  -1.          1.         -1.         -0.81342757]\n",
      " [ 0.5827164  -0.9999999  -0.9999993   0.9401039  -0.8222846 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9783739  -1.          1.         -1.         -0.97129875]\n",
      " [-0.9971186  -0.9792804   0.79844    -0.64475507 -0.16971755]\n",
      " [ 0.57230926 -1.          1.         -1.         -0.70548123]\n",
      " [ 0.9999481  -0.99691606  0.4274017  -0.9850408  -0.26429808]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * To nie było zbyt trudne, ale oczywiście, jeśli chcesz mieć możliwość uruchomienia RNN przez 100 iteracji to graf będzie dość duży. \n",
    "  * Teraz przyjrzyjmy się, jak stworzyć ten sam model za pomocą operacji RNN TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using static_rnn()\n",
    "\n",
    "  * Funkcja **static_rnn()** tworzy rozwiniętą sieć RNN przez  łaczenie komórek. \n",
    "  * Poniższy kod tworzy dokładnie ten sam model, co poprzedni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Najpierw tworzymy wejściowe placeholdery zastępcze, tak jak poprzednio. \n",
    "\n",
    "  * Następnie tworzymy BasicRNNCell, który można uznać za fabrykę, która tworzy kopie komórki, aby zbudować rozwinięty RNN (po jednym dla każdego kroku czasowego). \n",
    "  * Następnie wywołujemy static_rnn(), podając mu:\n",
    "    * fabrykę komórek \n",
    "    * tensory wejściowe\n",
    "    * i informując o typie danych wejściowych (służy to do utworzenia macierzy stanu początkowego, która domyślnie jest pełna zer). \n",
    "  * Funkcja static_rnn() wywołuje funkcję fabryczną komórki raz na wejście, tworząc dwie kopie komórki (każda zawierająca warstwę pięciu powtarzających się neuronów), ze wspólnymi wagami oraz biasy, i łączy je tak jak wcześniej . \n",
    "  * Funkcja static_rnn() zwraca dwa obiekty. \n",
    "    * Pierwszym jest lista Pythona zawierająca tensory wyjściowe dla każdego kroku czasowego. \n",
    "    * Drugi to tensor zawierający ostatnie stany sieci. \n",
    "  * Kiedy używasz komórek podstawowych, stan końcowy jest po prostu równy ostatniemu wynikowi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1376185   0.21949555 -0.61592793  0.56433624  0.65113115]\n",
      " [-0.5565757  -0.35894367 -0.9794814   0.9588838  -0.33179128]\n",
      " [-0.88409454 -0.7506628  -0.99909633  0.996841   -0.89899206]\n",
      " [-0.9975348  -0.6414948  -0.83871746  0.99752915 -0.9999351 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.92377996 -0.8825747  -0.99981666  0.98345184 -0.9992178 ]\n",
      " [ 0.35725626  0.58594644 -0.8181946  -0.55824023 -0.03909221]\n",
      " [-0.9304895  -0.67598426 -0.9986287   0.91753626 -0.9966239 ]\n",
      " [-0.7825352  -0.36849847 -0.96020097  0.42627504 -0.97051793]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Załużmy, że chcemy zrobić 50 kroków. \n",
    "  * W takiej sytuacji nie byłoby zbyt łatwo zdefiniować 50 symboli wejściowych i 50 tensorów wyjściowych. \n",
    "\n",
    "  * Co więcej, w czasie wykonywania musiałbyśmy zainicjalizować każdy z 50 obiektów zastępczych i manipulować 50 wyjściami. \n",
    "  \n",
    "  * Poniższy kod buduje ten sam RNN ponownie, ale tym razem wykorzystujemy jeden placeholder [Brak, n_steps, n_inputs], gdzie pierwszym wymiarem jest wielkością mini-bath. \n",
    "  \n",
    "  * Następnie wyodrębnia listę sekwencji wejściowych dla każdego kroku czasowego. \n",
    "  \n",
    "      * X_seqs powinien być lista n_steps tensowór o kształcie [None, n_inputs], w której pierwszym wymiarem jest rozmiarem mini-batch. \n",
    "  \n",
    "      * Aby to zrobić, najpierw zamieniamy dwa pierwsze wymiary za pomocą funkcji transpose(), aby kroki czasowe były teraz pierwszym wymiarem. \n",
    "      \n",
    "      * Następnie wyodrębniamy listę tensorów wzdłuż pierwszego wymiaru (tj. Jeden tensor na etap czasowy) za pomocą funkcji unstack().\n",
    "      \n",
    "  * Następne dwa wiersze są takie same jak wcześniej. \n",
    "  * Na koniec scalamy wszystkie tensory wyjściowe w jeden tensor za pomocą funkcji stack() aby otrzymać końcowy tensor kształtu [None, n_steps, n_neurons] (ponownie pierwszym wymiarem jest wielkością mini batha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs,\n",
    "                                                dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy uruchomić sieć, podając jej pojedynczy tensor, który zawiera wszystkie sekwencje mini-batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymujemy pojedynczy tensor **output_val** dla wszystkich instancji, wszystkich kroków czasowych i wszystkich neuronów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.6649127   0.82071596 -0.48354113 -0.88919264 -0.7478687 ]\n",
      "  [-0.98179144  0.9989492  -0.98389685  0.7443749  -0.99163437]]\n",
      "\n",
      " [[-0.9516823   0.99490875 -0.92497087 -0.93341523 -0.9742932 ]\n",
      "  [-0.32576984 -0.77630436  0.5023754   0.44608352 -0.37081614]]\n",
      "\n",
      " [[-0.9939281   0.9998678  -0.99131024 -0.9603593  -0.997652  ]\n",
      "  [-0.93323153  0.8879398  -0.8000195   0.8813868  -0.9528799 ]]\n",
      "\n",
      " [[-0.1395578   0.8392997   0.89317125  0.99993813 -0.8498562 ]\n",
      "  [ 0.03385155 -0.07713976  0.35224912  0.7651471  -0.48652583]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcja dynamic_rnn()\n",
    "\n",
    "  * Funkcja **dynamic_rnn()** używa operacji **while_loop()** do przepuszczenia przez neurony odpowiednią liczbę razy.\n",
    "\n",
    "  * Ponadto możesz ustawić **swap_memory = True**, jeśli chcesz zamienić pamięć GPU na pamięć CPU podczas wstecznej propagacji, aby uniknąć błędów OOM. \n",
    "\n",
    "  * Akceptuje on również pojedynczy tensor dla wszystkich wejść w każdym kroku czasowym (kształt [Brak, n_steps, n_inputs]) i zwraca pojedynczy tensor dla wszystkich wyjść w każdym kroku czasowym (kształt [Brak, n_steps, n_neurons])\n",
    "\n",
    "  * Nie ma potrzeby układania lub transpozycji. \n",
    "\n",
    "  * Poniższy kod tworzy ten sam RNN jak wcześniej przy użyciu funkcji dynamic_rnn (). Jest o wiele ładniej!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.6649127   0.82071596 -0.48354113 -0.88919264 -0.7478687 ]\n",
      "  [-0.98179144  0.9989492  -0.98389685  0.7443749  -0.99163437]]\n",
      "\n",
      " [[-0.9516823   0.99490875 -0.92497087 -0.93341523 -0.9742932 ]\n",
      "  [-0.32576984 -0.77630436  0.5023754   0.44608352 -0.37081614]]\n",
      "\n",
      " [[-0.9939281   0.9998678  -0.99131024 -0.9603593  -0.997652  ]\n",
      "  [-0.93323153  0.8879398  -0.8000195   0.8813868  -0.9528799 ]]\n",
      "\n",
      " [[-0.1395578   0.8392997   0.89317125  0.99993813 -0.8498562 ]\n",
      "  [ 0.03385155 -0.07713976  0.35224912  0.7651471  -0.48652583]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Variable Length Input Sequences\n",
    "\n",
    "  * Do tej pory używaliśmy tylko stałych sekwencji wejściowych (wszystkie dokładnie o dwa kroki). \n",
    "\n",
    "  * Co jeśli sekwencje wejściowe mają zmienne długości (np. Podobne zdania)? \n",
    "  \n",
    "  * W takim przypadku powinieneś ustawić parametr **sequence_length** przy wywołaniu funkcji **dynamic_rnn()** (lub static_rnn ()); \n",
    "  * musi to być tensor 1D, \n",
    "  * wskazuje on długość sekwencji wejściowej dla każdej instancji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    # step 0 step 1\n",
    "    [[0, 1, 2], [9, 8, 7]], # instance 0\n",
    "    [[3, 4, 5], [0, 0, 0]], # instance 1 (padded with a zero vector)\n",
    "    [[6, 7, 8], [6, 5, 4]], # instance 2\n",
    "    [[9, 0, 1], [3, 2, 1]], # instance 3\n",
    "])\n",
    "seq_length_batch = np.array([2, 1, 2, 2])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.78141797 -0.49851418 -0.14493392 -0.92397135  0.89701474]\n",
      "  [-0.94211817 -0.99670196  0.99974716 -1.          0.97302216]]\n",
      "\n",
      " [[-0.94907165 -0.93124336  0.8656041  -0.9999637   0.99156755]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.988933   -0.99245363  0.9922785  -1.          0.99933976]\n",
      "  [-0.4879012  -0.9825125   0.99266934 -0.99978286  0.8595685 ]]\n",
      "\n",
      " [[ 0.9999413  -0.98737895  0.999641   -0.9742392  -0.9910776 ]\n",
      "  [ 0.17476727 -0.40185434  0.9044615  -0.95206445  0.24472281]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.94211817 -0.99670196  0.99974716 -1.          0.97302216]\n",
      " [-0.94907165 -0.93124336  0.8656041  -0.9999637   0.99156755]\n",
      " [-0.4879012  -0.9825125   0.99266934 -0.99978286  0.8595685 ]\n",
      " [ 0.17476727 -0.40185434  0.9044615  -0.95206445  0.24472281]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
